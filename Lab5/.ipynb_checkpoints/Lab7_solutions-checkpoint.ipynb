{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a Naive Bayes Classifier\n",
    "\n",
    "Today we will be implementing a Naive Bayes Classifier from scratch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "def loadCsv(filename):\n",
    "    lines = csv.reader(open(filename, \"rt\"))\n",
    "    dataset = list(lines)\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = [float(x) for x in dataset[i]]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function reads the dataset(csv file) and converts the number strings into floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data file pima-indians-diabetes.data.csv with 768 rows\n"
     ]
    }
   ],
   "source": [
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "dataset = loadCsv(filename)\n",
    "print(('Loaded data file {0} with {1} rows').format(filename, len(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Fill out this function which splits the dataset into a training set and testing set, and returns the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#TODO\n",
    "def splitDataSet(dataset,splitRatio):\n",
    "    train_size = int(len(dataset)*splitRatio)    #Size of the training set\n",
    "    training_set = []  \n",
    "    copy = list(dataset)\n",
    "    #Extract training set from dataset using copy of the dataset. \n",
    "    while len(training_set) < train_size :\n",
    "        num = np.random.randint(0,len(copy)-1)\n",
    "        training_set.append(copy.pop(num))   \n",
    "    return [training_set,copy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 5 rows into train with [[2], [1], [4]] and test with [[3], [5]]\n"
     ]
    }
   ],
   "source": [
    "#This cell should run properly\n",
    "dataset = [[1], [2], [3], [4], [5]]\n",
    "splitRatio = 0.67\n",
    "train, test = splitDataSet(dataset, splitRatio)\n",
    "print(('Split {0} rows into train with {1} and test with {2}').format(len(dataset), train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Summarize Data\n",
    "\n",
    "Q2. Fill out this function which separates the data by class(labels). This function returns a dictionary which maps the class to the respective instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "def separatebyClass(dataset):\n",
    "    separated = {}\n",
    "    #Fill out this function\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        if(vector[-1] not in separated):\n",
    "            separated[vector[-1]] = []\n",
    "        separated[vector[-1]].append(vector)\n",
    "    return separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separated instances: {0: [[2, 21, 0]], 1: [[1, 20, 1], [3, 22, 1]]}\n"
     ]
    }
   ],
   "source": [
    "#This cell should run properly\n",
    "dataset = [[1,20,1], [2,21,0], [3,22,1]]\n",
    "separated = separatebyClass(dataset)\n",
    "print(('Separated instances: {0}').format(separated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. Fill out functions which return the mean and standard deviation of a list of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "#TODO\n",
    "def mean(numbers):\n",
    "    #Fill out this function\n",
    "    return sum(numbers)/float(len(numbers))\n",
    "\n",
    "def stdev(numbers):\n",
    "    #Fill out this function \n",
    "    avg = mean(numbers)\n",
    "    variance = sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1)\n",
    "    return math.sqrt(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean([4,1,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of [1, 2, 3, 4, 5]: mean=3.0, stdev=1.5811388300841898\n"
     ]
    }
   ],
   "source": [
    "#This cell should run properly\n",
    "numbers = [1,2,3,4,5]\n",
    "print(('Summary of {0}: mean={1}, stdev={2}').format(numbers, mean(numbers), stdev(numbers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Fill out a function which calculates the mean and standard deviation of each attribute in a class. The mean and standard deviation should be a tuple for each attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "def summarize(dataset):\n",
    "    summaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)]\n",
    "    del summaries[-1]\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2, 3), (20, 21, 22), (0, 1, 0)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in zip(*dataset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute summaries: [(2.0, 1.0), (21.0, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "#This cell should run properly\n",
    "dataset = [[1,20,0], [2,21,1], [3,22,0]]\n",
    "summary = summarize(dataset)\n",
    "print (('Attribute summaries: {0}').format(summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Fill out the function which summarizes each class. This function returns a dictionary which maps the class to the summary of the attributes of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "def summarizebyClass(dataset):\n",
    "    separated = separatebyClass(dataset)\n",
    "    summaries = {}\n",
    "    #Fill this out\n",
    "    for label in separated:\n",
    "        summaries[label] = summarize(separated[label])\n",
    "    return summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary by class value: {0: [(3.0, 1.0), (21.5, 0.5)], 1: [(2.0, 1.0), (21.0, 1.0)]}\n"
     ]
    }
   ],
   "source": [
    "#This should work properly\n",
    "dataset = [[1,20,1], [2,21,0], [3,22,1], [4,22,0]]\n",
    "summary = summarizebyClass(dataset)\n",
    "print(('Summary by class value: {0}').format(summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Make predictions\n",
    "\n",
    "Q6. Fill out the function which calculates the probability of a Gaussian distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "#TODO\n",
    "def calculateProbability(x,mean,stdev):\n",
    "    #Fill this out\n",
    "    exp = -(x - mean)**2/float(2*(stdev**2))\n",
    "    return np.exp(exp)/float(np.sqrt(2*np.pi)*stdev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of belonging to this class: 0.06248965759370005\n"
     ]
    }
   ],
   "source": [
    "#This cell should run properly\n",
    "x = 71.5\n",
    "mean = 73\n",
    "stdev = 6.2\n",
    "probability = calculateProbability(x, mean, stdev)\n",
    "print(('Probability of belonging to this class: {0}').format(probability))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. Fill out the function which calculates the probability that a data point belongs to either class. We can calculate the probabilities of an attribute belonging to a class using the above function, and we can combine the probabilities by multiplying them(Naive). Thus, this function returns a dictionary which shows the probability that the data summary belongs to a particular class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "def calculateClassProbabilities(summaries,inputVector):\n",
    "    probabilities = {}\n",
    "    for classValue,classSummaries in summaries.items():\n",
    "        #Fill this out\n",
    "        probabilities[classValue] = 1\n",
    "        for i in range(len(classSummaries)):\n",
    "            mean,stdev = classSummaries[i]\n",
    "            probabilities[classValue] *= calculateProbability(inputVector[i],mean,stdev)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities for each class: {0: 0.7820853879509118, 1: 6.298736258150442e-05}\n"
     ]
    }
   ],
   "source": [
    "#This cell should run properly\n",
    "summaries = {0:[(1, 0.5)], 1:[(20, 5.0)]}\n",
    "inputVector = [1.1, '?']\n",
    "probabilities = calculateClassProbabilities(summaries, inputVector)\n",
    "print(('Probabilities for each class: {0}').format(probabilities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8a. Fill out the function which makes the prediction that a datapoint belongs to a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "#TODO\n",
    "def predict(summaries,inputVector):\n",
    "    \n",
    "    probabilities = calculateClassProbabilities(summaries,inputVector)\n",
    "    \n",
    "    #Fill this function out\n",
    "    return max(probabilities.items(), key=operator.itemgetter(1))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: A\n"
     ]
    }
   ],
   "source": [
    "#This cell should run properly\n",
    "summaries = {'A':[(1, 0.5)], 'B':[(20, 5.0)]}\n",
    "inputVector = [1.1, '?']\n",
    "result = predict(summaries, inputVector)\n",
    "print(('Prediction: {0}').format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8b. Fill out this function for generating predictions for a list of test datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPredictions(summaries,testSet):\n",
    "    predictions = []\n",
    "    for i in range(len(testSet)):\n",
    "        predictions.append(predict(summaries,testSet[i]))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: ['A', 'B']\n"
     ]
    }
   ],
   "source": [
    "#This cell should run properly\n",
    "summaries = {'A':[(1, 0.5)], 'B':[(20, 5.0)]}\n",
    "testSet = [[1.1, '?'], [19.1, '?']]\n",
    "predictions = getPredictions(summaries, testSet)\n",
    "print(('Predictions: {0}').format(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Get Accuracy\n",
    "\n",
    "Q9. Fill out this function which returns the accuracy of the predictions generated by the Naive Bayes Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "def getAccuracy(testSet,predictions):\n",
    "    \n",
    "    return sum([1 for test,y_pred in zip(testSet,predictions) if test[-1]==y_pred])/float(len(testSet))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.66666666666666\n"
     ]
    }
   ],
   "source": [
    "#This cell should run properly\n",
    "testSet = [[1,1,1,'a'], [2,2,2,'a'], [3,3,3,'b']]\n",
    "predictions = ['a', 'a', 'a']\n",
    "accuracy = getAccuracy(testSet, predictions)\n",
    "print(('Accuracy: {0}').format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Combine it all\n",
    "\n",
    "Q10. Fill out this Naive Bayes function which takes in the filename and prints its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "def NaiveBayesClassifier(filename):\n",
    "    dataset = loadCsv(filename)\n",
    "    splitRatio = 0.67\n",
    "    train,test = splitDataSet(dataset,splitRatio)\n",
    "    print(('Split {0} rows into train={1} and test={2} rows').format(len(dataset), len(train), len(test)))\n",
    "    \n",
    "    summaries = summarizebyClass(train)\n",
    "    preds = getPredictions(summaries,test)\n",
    "    \n",
    "    return getAccuracy(test,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 768 rows into train=514 and test=254 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "75.98425196850394"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This cell should run properly\n",
    "NaiveBayesClassifier('pima-indians-diabetes.data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
