{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a Naive Bayes Classifier\n",
    "\n",
    "Today we will be implementing a Naive Bayes Classifier from scratch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "def loadCsv(filename):\n",
    "    lines = csv.reader(open(filename, \"rt\"))\n",
    "    dataset = list(lines)\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = [float(x) for x in dataset[i]]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function reads the dataset(csv file) and converts the number strings into floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data file pimaindiansdiabetes.data.csv with 768 rows\n"
     ]
    }
   ],
   "source": [
    "filename = 'pimaindiansdiabetes.data.csv'\n",
    "dataset = loadCsv(filename)\n",
    "print(('Loaded data file {0} with {1} rows').format(filename, len(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Fill out this function which splits the dataset into a training set and testing set, and returns the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#TODO\n",
    "def splitDataSet(dataset,splitRatio):\n",
    "    train_size = int(len(dataset)*splitRatio)    #Size of the training set\n",
    "    training_set = []  \n",
    "    copy = list(dataset)\n",
    "    #Extract training set from dataset using copy of the dataset. \n",
    "    while len(training_set) < train_size :\n",
    "        num = np.random.randint(0,len(copy)-1)\n",
    "        training_set.append(copy.pop(num))   \n",
    "    return [training_set,copy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 5 rows into train with [[3], [2], [4]] and test with [[1], [5]]\n"
     ]
    }
   ],
   "source": [
    "#This cell should run properly\n",
    "dataset = [[1], [2], [3], [4], [5]]\n",
    "splitRatio = 0.67\n",
    "train, test = splitDataSet(dataset, splitRatio)\n",
    "print(('Split {0} rows into train with {1} and test with {2}').format(len(dataset), train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Summarize Data\n",
    "\n",
    "Q2. Fill out this function which separates the data by class(labels). This function returns a dictionary which maps the class to the respective instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "def separatebyClass(dataset):\n",
    "    separated = {}\n",
    "    #Fill out this function\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        if(vector[-1] not in separated):\n",
    "            separated[vector[-1]] = []\n",
    "        separated[vector[-1]].append(vector)\n",
    "    return separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separated instances: {1: [[1, 20, 1], [3, 22, 1]], 0: [[2, 21, 0]]}\n"
     ]
    }
   ],
   "source": [
    "#This cell should run properly\n",
    "dataset = [[1,20,1], [2,21,0], [3,22,1]]\n",
    "separated = separatebyClass(dataset)\n",
    "print(('Separated instances: {0}').format(separated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. Fill out functions which return the mean and standard deviation of a list of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "#TODO\n",
    "def mean(numbers):\n",
    "    #Fill out this function\n",
    "    return sum(numbers)/float(len(numbers))\n",
    "\n",
    "def stdev(numbers):\n",
    "    #Fill out this function \n",
    "    avg = mean(numbers)\n",
    "    variance = sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1)\n",
    "    return math.sqrt(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean([4,1,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of [1, 2, 3, 4, 5]: mean=3.0, stdev=1.5811388300841898\n"
     ]
    }
   ],
   "source": [
    "#This cell should run properly\n",
    "numbers = [1,2,3,4,5]\n",
    "print(('Summary of {0}: mean={1}, stdev={2}').format(numbers, mean(numbers), stdev(numbers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Fill out a function which calculates the mean and standard deviation of each attribute in a class. The mean and standard deviation should be a tuple for each attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "def summarize(dataset):\n",
    "    summaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)]\n",
    "    del summaries[-1]\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2, 3), (20, 21, 22), (1, 0, 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in zip(*dataset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute summaries: [(2.0, 1.0), (21.0, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "#This cell should run properly\n",
    "dataset = [[1,20,0], [2,21,1], [3,22,0]]\n",
    "summary = summarize(dataset)\n",
    "print (('Attribute summaries: {0}').format(summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Fill out the function which summarizes each class. This function returns a dictionary which maps the class to the summary of the attributes of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "def summarizebyClass(dataset):\n",
    "    separated = separatebyClass(dataset)\n",
    "    summaries = {}\n",
    "    #Fill this out\n",
    "    for label in separated:\n",
    "        summaries[label] = summarize(separated[label])\n",
    "    return summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary by class value: {1: [(2.0, 1.4142135623730951), (21.0, 1.4142135623730951)], 0: [(3.0, 1.4142135623730951), (21.5, 0.7071067811865476)]}\n"
     ]
    }
   ],
   "source": [
    "#This should work properly\n",
    "dataset = [[1,20,1], [2,21,0], [3,22,1], [4,22,0]]\n",
    "summary = summarizebyClass(dataset)\n",
    "print(('Summary by class value: {0}').format(summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Make predictions\n",
    "\n",
    "Q6. Fill out the function which calculates the probability of a Gaussian distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "#TODO\n",
    "def calculateProbability(x,mean,stdev):\n",
    "    #Fill this out\n",
    "    exp = -(x - mean)**2/float(2*(stdev**2))\n",
    "    return np.exp(exp)/float(np.sqrt(2*np.pi)*stdev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of belonging to this class: 0.06248965759370005\n"
     ]
    }
   ],
   "source": [
    "#This cell should run properly\n",
    "x = 71.5\n",
    "mean = 73\n",
    "stdev = 6.2\n",
    "probability = calculateProbability(x, mean, stdev)\n",
    "print(('Probability of belonging to this class: {0}').format(probability))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. Fill out the function which calculates the probability that a data point belongs to either class. We can calculate the probabilities of an attribute belonging to a class using the above function, and we can combine the probabilities by multiplying them(Naive). Thus, this function returns a dictionary which shows the probability that the data summary belongs to a particular class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "def calculateClassProbabilities(summaries,inputVector):\n",
    "    probabilities = {}\n",
    "    for classValue,classSummaries in summaries.items():\n",
    "        #Fill this out\n",
    "        probabilities[classValue] = 1\n",
    "        for i in range(len(classSummaries)):\n",
    "            mean,stdev = classSummaries[i]\n",
    "            probabilities[classValue] *= calculateProbability(inputVector[i],mean,stdev)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities for each class: {0: 0.78208538795091176, 1: 6.2987362581504424e-05}\n"
     ]
    }
   ],
   "source": [
    "#This cell should run properly\n",
    "summaries = {0:[(1, 0.5)], 1:[(20, 5.0)]}\n",
    "inputVector = [1.1, '?']\n",
    "probabilities = calculateClassProbabilities(summaries, inputVector)\n",
    "print(('Probabilities for each class: {0}').format(probabilities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8a. Fill out the function which makes the prediction that a datapoint belongs to a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "#TODO\n",
    "def predict(summaries,inputVector):\n",
    "    \n",
    "    probabilities = calculateClassProbabilities(summaries,inputVector)\n",
    "    \n",
    "    #Fill this function out\n",
    "    return max(probabilities.items(), key=operator.itemgetter(1))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: A\n"
     ]
    }
   ],
   "source": [
    "#This cell should run properly\n",
    "summaries = {'A':[(1, 0.5)], 'B':[(20, 5.0)]}\n",
    "inputVector = [1.1, '?']\n",
    "result = predict(summaries, inputVector)\n",
    "print(('Prediction: {0}').format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8b. Fill out this function for generating predictions for a list of test datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPredictions(summaries,testSet):\n",
    "    predictions = []\n",
    "    for i in range(len(testSet)):\n",
    "        predictions.append(predict(summaries,testSet[i]))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: ['A', 'B']\n"
     ]
    }
   ],
   "source": [
    "#This cell should run properly\n",
    "summaries = {'A':[(1, 0.5)], 'B':[(20, 5.0)]}\n",
    "testSet = [[1.1, '?'], [19.1, '?']]\n",
    "predictions = getPredictions(summaries, testSet)\n",
    "print(('Predictions: {0}').format(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Get Accuracy\n",
    "\n",
    "Q9. Fill out this function which returns the accuracy of the predictions generated by the Naive Bayes Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "def getAccuracy(testSet,predictions):\n",
    "    \n",
    "    return sum([1 for test,y_pred in zip(testSet,predictions) if test[-1]==y_pred])/float(len(testSet))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.66666666666666\n"
     ]
    }
   ],
   "source": [
    "#This cell should run properly\n",
    "testSet = [[1,1,1,'a'], [2,2,2,'a'], [3,3,3,'b']]\n",
    "predictions = ['a', 'a', 'a']\n",
    "accuracy = getAccuracy(testSet, predictions)\n",
    "print(('Accuracy: {0}').format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Combine it all\n",
    "\n",
    "Q10. Fill out this Naive Bayes function which takes in the filename and prints its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "def NaiveBayesClassifier(filename):\n",
    "    dataset = loadCsv(filename)\n",
    "    splitRatio = 0.67\n",
    "    train,test = splitDataSet(dataset,splitRatio)\n",
    "    print(('Split {0} rows into train={1} and test={2} rows').format(len(dataset), len(train), len(test)))\n",
    "    \n",
    "    summaries = summarizebyClass(train)\n",
    "    preds = getPredictions(summaries,test)\n",
    "    \n",
    "    return getAccuracy(test,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 768 rows into train=514 and test=254 rows\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-143bde963ad2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#This cell should run properly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mNaiveBayesClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pimaindiansdiabetes.data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-496d6e1fe902>\u001b[0m in \u001b[0;36mNaiveBayesClassifier\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Split {0} rows into train={1} and test={2} rows'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msummaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarizebyClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetPredictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummaries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-f38a8ade39ee>\u001b[0m in \u001b[0;36msummarizebyClass\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#Fill this out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseparated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0msummaries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseparated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msummaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-99b81a2181a8>\u001b[0m in \u001b[0;36msummarize\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msummaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0msummaries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msummaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-99b81a2181a8>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msummaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0msummaries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msummaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "#This cell should run properly\n",
    "NaiveBayesClassifier('pimaindiansdiabetes.data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
