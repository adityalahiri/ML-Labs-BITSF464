{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('Training_Set.csv')\n",
    "test_df = pd.read_csv('Testing_Set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separating X and y\n",
    "\n",
    "y = train_df['count']\n",
    "X = train_df.drop(['count'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X\n",
    "y_train = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train Test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_scale = ['season', 'holiday', 'workingday', 'weather', 'temp',\n",
    "       'atemp', 'humidity', 'windspeed', 'casual', 'registered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arrayslayer/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/arrayslayer/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/home/arrayslayer/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalar = StandardScaler()\n",
    "X_train[to_scale] = scalar.fit_transform(X_train[to_scale])\n",
    "X_test[to_scale] = scalar.transform(X_test[to_scale])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arrayslayer/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_train.drop(['datetime'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.75, loss='ls', max_depth=4, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=1400, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingRegressor(max_depth=4,learning_rate=0.75,n_estimators=1400)\n",
    "gb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arrayslayer/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_test.drop(['datetime'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "\n",
    "#TODO\n",
    "\n",
    "gb = GradientBoostingRegressor(n_estimators=500,learning_rate=0.75)        #Initialize the classifier object\n",
    "\n",
    "parameters = {'n_estimators':[500,600,800],'learning_rate':[0.5,0.75,1.0,1.25],'max_depth':[4,6,8,10]}#Dictionary of parameters\n",
    "\n",
    "scorer = make_scorer(mean_squared_log_error)         #Initialize the scorer using make_scorer\n",
    "\n",
    "grid_obj = GridSearchCV(gb,parameters)         #Initialize a GridSearchCV object with above parameters,scorer and classifier\n",
    "\n",
    "grid_fit = grid_obj.fit(X_train,y_train)        #Fit the gridsearch object with X_train,y_train\n",
    "\n",
    "best_gb = grid_fit.best_estimator_         #Get the best estimator. For this, check documentation of GridSearchCV object\n",
    "\n",
    "#y_pred = best_clf.predict(X_test)\n",
    "\n",
    "\n",
    "#rmsle = np.sqrt(mean_squared_log_error(y_test, y_pred))       #Calculate accuracy for unoptimized model\n",
    "\n",
    "#print(\" score on optimized model:{}\".format(rmsle))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.5, loss='ls', max_depth=4, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=800, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gb.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0507297184886\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "y_pred = gb.predict(X_test)\n",
    "print(np.sqrt(mean_squared_log_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.5, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=600, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gb.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 19697.25410756\n",
      "Iteration 2, loss = 1712.27915222\n",
      "Iteration 3, loss = 355.89741659\n",
      "Iteration 4, loss = 96.46029175\n",
      "Iteration 5, loss = 35.37887991\n",
      "Iteration 6, loss = 20.07613182\n",
      "Iteration 7, loss = 14.54572096\n",
      "Iteration 8, loss = 11.30559183\n",
      "Iteration 9, loss = 9.48066474\n",
      "Iteration 10, loss = 8.25071556\n",
      "Iteration 11, loss = 7.18800103\n",
      "Iteration 12, loss = 6.35382853\n",
      "Iteration 13, loss = 5.69680111\n",
      "Iteration 14, loss = 5.20772060\n",
      "Iteration 15, loss = 4.86234419\n",
      "Iteration 16, loss = 4.56544134\n",
      "Iteration 17, loss = 4.34994831\n",
      "Iteration 18, loss = 4.11153359\n",
      "Iteration 19, loss = 3.64377762\n",
      "Iteration 20, loss = 3.45595669\n",
      "Iteration 21, loss = 3.29578469\n",
      "Iteration 22, loss = 3.09716402\n",
      "Iteration 23, loss = 2.98822932\n",
      "Iteration 24, loss = 2.72377405\n",
      "Iteration 25, loss = 2.72333854\n",
      "Iteration 26, loss = 2.57245994\n",
      "Iteration 27, loss = 2.42173870\n",
      "Iteration 28, loss = 2.31687641\n",
      "Iteration 29, loss = 2.23097217\n",
      "Iteration 30, loss = 2.35043446\n",
      "Iteration 31, loss = 2.23203981\n",
      "Iteration 32, loss = 2.05573931\n",
      "Iteration 33, loss = 1.97045384\n",
      "Iteration 34, loss = 2.10197798\n",
      "Iteration 35, loss = 2.16210860\n",
      "Iteration 36, loss = 1.92650267\n",
      "Iteration 37, loss = 1.95061076\n",
      "Iteration 38, loss = 1.66925178\n",
      "Iteration 39, loss = 1.60352443\n",
      "Iteration 40, loss = 1.59274220\n",
      "Iteration 41, loss = 1.49843059\n",
      "Iteration 42, loss = 1.84473287\n",
      "Iteration 43, loss = 1.49861549\n",
      "Iteration 44, loss = 1.44155482\n",
      "Iteration 45, loss = 1.86627154\n",
      "Iteration 46, loss = 1.39200345\n",
      "Iteration 47, loss = 1.45342182\n",
      "Iteration 48, loss = 1.36604038\n",
      "Iteration 49, loss = 1.26467640\n",
      "Iteration 50, loss = 1.29240289\n",
      "Iteration 51, loss = 1.56451179\n",
      "Iteration 52, loss = 1.97455450\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "reg = MLPRegressor(hidden_layer_sizes=(100,200,300,400,300,200,100),verbose = True)\n",
    "reg.fit(X=X_train,y=y_train)\n",
    "y_pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best'),\n",
       "         learning_rate=1.0, loss='linear', n_estimators=500,\n",
       "         random_state=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "dtree = DecisionTreeRegressor()\n",
    "clf = AdaBoostRegressor(base_estimator=dtree,n_estimators = 500,learning_rate=1.6)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df[to_scale] = scalar.transform(test_df[to_scale])\n",
    "dt = test_df['datetime']\n",
    "test_df.drop(['datetime'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_final_test_reg = reg.predict(test_df)\n",
    "\n",
    "y_final_test_ada = clf.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final_test_gb = gb.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_final = (y_final_test_ada + y_final_test_reg)/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_df = pd.DataFrame(data=y_final_test_gb,index=dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ans_df.to_csv('ans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
